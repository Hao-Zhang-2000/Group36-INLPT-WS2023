{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4543a6e6-caf9-48f9-867e-c305c6ce61a9",
   "metadata": {},
   "source": [
    "## Collect Questions used for collecting training data from GPT3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e8512f-79fb-4929-aa70-0f9ef2cde8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6726fb-daf8-4f74-aa98-d8d85e089256",
   "metadata": {},
   "source": [
    "One user prompt for generating relevant questions and one for generating random questions that the teacher model should refuse to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653e6c4c-2068-4654-b379-3f775730564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_med = \"Please generate *200* highly varied questions a person, doctor or scientist might ask about topics related to 'Intelligence', 'Brain Activits' and other tangentially related topics. Format your answer as an enumerated markdown list. Do not answer with anything but with said list.\"\n",
    "user_prompt_rand = \"Please generate *200* highly varied questions. It doesn't matter what topic the questions are aimed at. Format your answer as an enumerated markdown list. Do not answer with anything but with said list.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a925fd9-a574-4fd7-aab1-c29a1aa23d97",
   "metadata": {},
   "source": [
    "Collect 20 * 200 questions from GPT4 turbo, deduplicate and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005cce65-ae4f-4f0d-8409-5966490a1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_questions = []\n",
    "for _ in tqdm(range(20)):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo-preview\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\",   \"content\": user_prompt_med},\n",
    "        ],\n",
    "        temperature = 0.8\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    new_questions = [\".\".join(line.split('.')[1:]) for line in response.split('\\n')]\n",
    "    medical_questions.extend(new_questions)\n",
    "medical_questions = list(set(medical_questions))\n",
    "with open(\"training_data/medical_questions.json\", \"w+\") as f:\n",
    "    f.write(json.dumps(medical_questions, indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da13ff-7721-45e9-84db-4a7cab125bc6",
   "metadata": {},
   "source": [
    "Collect 2 * 200 random questions, deduplicate them and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75beb7-bc9b-48e0-ab3b-ea964c380c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_questions = []\n",
    "for _ in tqdm(range(2)):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo-preview\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\",   \"content\": user_prompt_rand},\n",
    "        ],\n",
    "        temperature = 0.8\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    new_questions = [\".\".join(line.split('.')[1:]) for line in response.split('\\n')]\n",
    "    random_questions.extend(new_questions)\n",
    "random_questions = list(set(random_questions))\n",
    "print(len(random_questions))\n",
    "with open(\"training_data/random_questions.json\", \"w+\") as f:\n",
    "    f.write(json.dumps(random_questions, indent=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d29a3-ad61-4916-a171-5116e3482406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
