{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e8512f-79fb-4929-aa70-0f9ef2cde8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653e6c4c-2068-4654-b379-3f775730564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_med = \"Please generate *200* highly varied questions a person, doctor or scientist might ask about topics related to 'Intelligence', 'Brain Activits' and other tangentially related topics. Format your answer as an enumerated markdown list. Do not answer with anything but with said list.\"\n",
    "user_prompt_rand = \"Please generate *200* highly varied questions. It doesn't matter what topic the questions are aimed at. Format your answer as an enumerated markdown list. Do not answer with anything but with said list.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005cce65-ae4f-4f0d-8409-5966490a1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [46:05<00:00, 138.25s/it]\n"
     ]
    }
   ],
   "source": [
    "medical_questions = []\n",
    "for _ in tqdm(range(20)):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo-preview\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\",   \"content\": user_prompt_med},\n",
    "        ],\n",
    "        temperature = 0.8\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    new_questions = [\".\".join(line.split('.')[1:]) for line in response.split('\\n')]\n",
    "    medical_questions.extend(new_questions)\n",
    "medical_questions = list(set(medical_questions))\n",
    "with open(\"training_data/medical_questions.json\", \"w+\") as f:\n",
    "    f.write(json.dumps(medical_questions, indent=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b75beb7-bc9b-48e0-ab3b-ea964c380c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 2/2 [03:59<00:00, 119.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random_questions = []\n",
    "for _ in tqdm(range(2)):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo-preview\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\",   \"content\": user_prompt_rand},\n",
    "        ],\n",
    "        temperature = 0.8\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    new_questions = [\".\".join(line.split('.')[1:]) for line in response.split('\\n')]\n",
    "    random_questions.extend(new_questions)\n",
    "random_questions = list(set(random_questions))\n",
    "print(len(random_questions))\n",
    "with open(\"training_data/random_questions.json\", \"w+\") as f:\n",
    "    f.write(json.dumps(random_questions, indent=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d29a3-ad61-4916-a171-5116e3482406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
